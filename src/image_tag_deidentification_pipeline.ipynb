{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5726d0b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pydicom\n",
    "import random\n",
    "import time\n",
    "import csv\n",
    "import string\n",
    "import re\n",
    "import pandas as pd\n",
    "from pydicom.tag import Tag\n",
    "from pydicom.filereader import dcmread\n",
    "from datetime import datetime\n",
    "from pydicom.filewriter import dcmwrite\n",
    "import csv\n",
    "import time\n",
    "import dotenv\n",
    "dotenv.load_dotenv(\"../config/.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ba8cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "### This notebook contains work done for DICOM image tag de-identification, primarily using the pydicom library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fc7c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_folder(path, target):\n",
    "    result = None\n",
    "    for root, dirs, files in os.walk(path):\n",
    "        if target in dirs:\n",
    "            result= os.path.join(root, target)\n",
    "    if result:\n",
    "        print(f'Folder found at: {result}')\n",
    "    else:\n",
    "        print('Folder not found.')\n",
    "    \n",
    "    return result\n",
    "\n",
    "DIRECTORY = os.getenv(\"DIRECTORY\")\n",
    "# target_folder = 'E'\n",
    "# result = find_folder(DIRECTORY, target_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ca0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_identifiers(dicom_file):\n",
    "    tags_to_remove = [\n",
    "        'PatientID',\n",
    "        'PatientName', \n",
    "        'PatientSex',\n",
    "        'PatientBirthDate',\n",
    "        'PatientAge',\n",
    "        'StudyID',\n",
    "        'SeriesDate',\n",
    "        'SeriesTime',\n",
    "        'PatientWeight'\n",
    "    ]\n",
    "\n",
    "    for tag in tags_to_remove:\n",
    "        if tag in dicom_file:\n",
    "            del dicom_file[tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2b00fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_identifiers_with_pseudonyms(dicom_file):\n",
    "\n",
    "    \"\"\"\n",
    "    Replaces sensitive identifiers in a DICOM file with pseudonyms.\n",
    "\n",
    "    Parameters:\n",
    "    dicom_file: The DICOM file object to be processed.\n",
    "\n",
    "    The function performs the following steps:\n",
    "    1. Sets new values for patient name, manufacturer, and institution address to \"ERADICATED\".\n",
    "    2. Defines lists of keywords to remove and keywords to save.\n",
    "    3. Iterates over all tags in the DICOM dataset:\n",
    "       - Checks if the tag name contains any keyword from the removal list.\n",
    "       - If a keyword is found and not in the save list, replaces the tag value based on its VR (Value Representation):\n",
    "         - String types (LO, SH, PN, LT, ST, UT, DA, TM, DT, CS, UI) are replaced with \"ERADICATED\".\n",
    "         - Integer types (IS, SL, SS, UL, US) are replaced with 0.\n",
    "         - Decimal types (DS, FD, FL) are replaced with 0.0.\n",
    "         - Byte types (OB, OW, UN) are replaced with bytes(\"ERADICATED\", 'utf-8').\n",
    "       - Prints a message for tags with VRs not handled by the code.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    new_patient_name = \"ERADICATED\"\n",
    "    new_manufacturer = \"ERADICATED\"\n",
    "    new_institution_address = \"ERADICATED\"\n",
    "    \n",
    "    dicom_file.PatientName = new_patient_name\n",
    "    dicom_file.Manufacturer = new_manufacturer\n",
    "    dicom_file.InstitutionAddress = new_institution_address\n",
    "    keywords = [\"Private\", 'private', 'ID', 'Branch of Service', 'Date', 'Time', 'date', 'time', 'Name', 'name', \n",
    "            'Physician', 'Address', 'address', 'Admitting Diagnoses Description', 'UID', 'Unknown'] ## to remove\n",
    "    \n",
    "    keywords_to_save = ['Acquisition Date', 'Acquisition Time']\n",
    "    # Iterate over all the tags in the DICOM dataset\n",
    "    for tag in dicom_file.keys():\n",
    "        # Get the element corresponding to the tag\n",
    "        elem = dicom_file[tag]\n",
    "\n",
    "        # Check if the keyword is in the tag name\n",
    "        for keyword in keywords:\n",
    "            if keyword in keywords_to_save:\n",
    "                continue\n",
    "            if keyword in str(elem.name):\n",
    "                if elem.VR in [\"LO\", \"SH\", \"PN\", \"LT\", \"ST\", \"UT\", \"DA\", \"TM\", \"DT\", \"CS\", \"UI\"]:\n",
    "                # The VR is a string type, so convert the new value to a string\n",
    "                    dicom_file[tag].value = 'ERADICATED'\n",
    "                elif elem.VR in  [\"IS\", \"SL\", \"SS\", \"UL\", \"US\"]:\n",
    "                # The VR is an integer type, so convert the new value to an integer\n",
    "                    dicom_file[tag].value = 0\n",
    "                elif elem.VR in [\"DS\", \"FD\", \"FL\"]:\n",
    "                # The VR is a decimal type, so convert the new value to a float\n",
    "                    dicom_file[tag].value = 0.0\n",
    "                elif elem.VR in [\"OB\", \"OW\", \"UN\"]:\n",
    "                # The VR is other byte, so convert the new value to bytes\n",
    "                    dicom_file[tag].value = bytes('ERADICATED', 'utf-8')\n",
    "                else:\n",
    "                    print(f\"The tag {tag} has VR {elem.VR}, which is not handled in this code.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd643c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_digits(num_str, num):\n",
    "    num_str = str(num_str)\n",
    "    return num_str.zfill(num)\n",
    "\n",
    "def get_folders_in_path(path):\n",
    "    folders = []\n",
    "    while True:\n",
    "        path, folder = os.path.split(path)\n",
    "\n",
    "        if folder != \"\":\n",
    "            folders.append(folder)\n",
    "        else:\n",
    "            if path != \"\":\n",
    "                folders.append(path)\n",
    "            break\n",
    "\n",
    "    folders.reverse()\n",
    "    return folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a00ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_attribute_value(input_file, attr):\n",
    "    tags = [attr]\n",
    "    dicom_file = pydicom.dcmread(input_file)\n",
    "    attr_value = None\n",
    "    for key in dicom_file.keys():\n",
    "        elem = dicom_file[key]\n",
    "        for tag in tags:\n",
    "            if tag == str(elem.name):\n",
    "                attr_value = dicom_file[key].value\n",
    "    return attr_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4f6310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_date_check(date_str):\n",
    "    date_format = \"%Y%m%d\"\n",
    "    date = datetime.strptime(date_str, date_format)\n",
    "    return date >= datetime(2019, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e33cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_csv(data, filename):\n",
    "    with open(filename, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49179b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import mean\n",
    "def count_files_in_directory(directory):\n",
    "    mr_count = [0]\n",
    "    ct_count = [0]\n",
    "    xr_count = [0]\n",
    "    us_count = [0]\n",
    "    other_count = [0]\n",
    "    \n",
    "    \n",
    "    folder_count = 0\n",
    "    for root, dirs, files in os.walk(directory):\n",
    "        if root.count(os.sep) == directory.count(os.sep):\n",
    "            folder_count +=1\n",
    "#             print(f'Entering new folder at first level: {root}. This is folder number {folder_count} at this level.')\n",
    "            mr_count.append(0)\n",
    "            ct_count.append(0)\n",
    "            xr_count.append(0)\n",
    "            us_count.append(0)\n",
    "            other_count.append(0)\n",
    "            \n",
    "        if \"\\MR\" in root:\n",
    "            mr_count[folder_count] += len(files)\n",
    "        elif \"\\CT\" in root:\n",
    "            ct_count[folder_count] += len(files)\n",
    "        elif \"\\XR\" or '\\XA' or '\\DX' in root:\n",
    "            xr_count[folder_count] += len(files)\n",
    "        elif 'US' in root:\n",
    "            us_count[folder_count] += len(files)\n",
    "        else:\n",
    "            if 'SR' not in root or 'PR' not in root:\n",
    "                other_count[folder_count] += len(files)\n",
    "        \n",
    "        \n",
    "#         print(f'The directory {root} has {len(files)} files.')\n",
    "    \n",
    "    xr_count = [i for i in xr_count if i != 0]\n",
    "    mr_count = [i for i in mr_count if i != 0]\n",
    "    us_count = [i for i in us_count if i != 0]\n",
    "    ct_count = [i for i in ct_count if i != 0]\n",
    "    other_count = [i for i in other_count if i != 0]\n",
    "    \n",
    "    if len(xr_count) != 0:\n",
    "        print('XR avg:', mean(xr_count))\n",
    "    if len(mr_count) != 0:\n",
    "        print('MR avg:', mean(mr_count))\n",
    "    if len(us_count) != 0:\n",
    "        print('US avg:', mean(us_count))\n",
    "    if len(ct_count) != 0:\n",
    "        print('CT avg:', mean(ct_count))\n",
    "    if len(other_count) != 0:\n",
    "        print('Other avg:', mean(other_count))\n",
    "\n",
    "    return xr_count, mr_count, us_count, ct_count, other_count\n",
    "    \n",
    "# Replace 'your_directory_path' with the path of the directory you want to walk through\n",
    "YOUR_DIRECTORY_PATH = os.getenv(\"YOUR_DIRECTORY_PATH\")\n",
    "xr_count, mr_count, us_count, ct_count, other_count = count_files_in_directory(YOUR_DIRECTORY_PATH)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e8de8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statistics import median\n",
    "\n",
    "print('MR Stats:')\n",
    "print('Median:', median(mr_count))\n",
    "print('Mean:', mean(mr_count))\n",
    "print('Max:', max(mr_count))\n",
    "print('Min:', min(mr_count))\n",
    "print()\n",
    "print('XR Stats:')\n",
    "print('Median:', median(xr_count))\n",
    "print('Mean:', mean(xr_count))\n",
    "print('Max:', max(xr_count))\n",
    "print('Min:', min(xr_count))\n",
    "print()\n",
    "print('CT Stats:')\n",
    "print('Median:', median(ct_count))\n",
    "print('Mean:', mean(ct_count))\n",
    "print('Max:', max(ct_count))\n",
    "print('Min:', min(ct_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8429176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_process_directory(input_directory, output_directory, skip_files):\n",
    "    \n",
    "    \"\"\"\n",
    "    Processes DICOM files in a directory, anonymizes them, and saves the results to a new directory.\n",
    "\n",
    "    Parameters:\n",
    "    input_directory (str): The path to the directory containing the input DICOM files.\n",
    "    output_directory (str): The path to the directory where the processed files will be saved.\n",
    "    skip_files (bool): Whether to skip files that have already been processed.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A DataFrame containing information about the processed files.\n",
    "\n",
    "    The function performs the following steps:\n",
    "    1. Initializes lists to store various attributes of the DICOM files.\n",
    "    2. Reads a CSV file to get the list of folders to keep.\n",
    "    3. If skip_files is True, reads another CSV file to get the list of files to skip and updates the person IDs.\n",
    "    4. Iterates over the folders to keep and processes each DICOM file:\n",
    "       - Checks if the file should be skipped.\n",
    "       - Extracts attributes such as study date, study time, series number, instance number, modality, accession number, and study description.\n",
    "       - Updates lists with these attributes.\n",
    "       - Generates a new file name based on the extracted attributes and person ID.\n",
    "       - Anonymizes the DICOM file and saves it to the output directory.\n",
    "       - Updates a CSV file with information about the processed file.\n",
    "    5. Creates a DataFrame with the collected attributes and prints it.\n",
    "    6. Returns the DataFrame.\n",
    "\n",
    "    Note:\n",
    "    - The function assumes the existence of helper functions such as get_attribute_value, image_date_check, convert_to_digits, remove_identifiers, replace_identifiers_with_pseudonyms, and update_csv.\n",
    "    - The function also assumes the existence of the dcmread and dcmwrite functions for reading and writing DICOM files.\n",
    "    \"\"\"\n",
    "\n",
    "    old_names = []\n",
    "    all_path_folders = []\n",
    "    folders_broken_out = [[],[],[],[]]\n",
    "    new_names = []\n",
    "    study_descs = []\n",
    "    study_dates = []\n",
    "    study_times = []\n",
    "    series_nums = []\n",
    "    instance_nums = []\n",
    "    accession_nums = []\n",
    "    mods = []\n",
    "    processed_count = 0\n",
    "\n",
    "    IMAGES_PROCESSED = os.getenv(\"IMAGES_PROCESSED\")\n",
    "    SAMPLED_DATA_FOLDER_NAMES = os.getenv(\"SAMPLED_DATA_FOLDER_NAMES\")\n",
    "    \n",
    "    sampled_df = pd.read_csv(SAMPLED_DATA_FOLDER_NAMES)\n",
    "    \n",
    "    folders_to_keep = sampled_df['FolderName'].tolist()\n",
    "    \n",
    "    if skip_files:\n",
    "        files_to_skip_df = pd.read_csv(IMAGES_PROCESSED)\n",
    "        files_to_skip_df = files_to_skip_df.dropna()\n",
    "        files_to_skip_df.to_csv(IMAGES_PROCESSED, index=False)\n",
    "        \n",
    "        files_to_skip_df.columns = ['Filename', 'PersonID','New_Filename', 'MRN', 'AccessionNBR',\n",
    "                                    'Modality', 'Modality_Subtype', 'Date', 'Time', 'Series_Num', 'Instance_Num']\n",
    "        # Get the first column\n",
    "        files_to_skip = set((files_to_skip_df['Filename']))\n",
    "        \n",
    "        person_ids_completed = files_to_skip_df[['PersonID', 'MRN']].values.tolist()\n",
    "        person_ids_completed = set(tuple(x) for x in person_ids_completed)\n",
    "        person_ids = {str(int(t[1])): str(int(t[0])) for t in person_ids_completed}\n",
    "        person_id = max(person_ids.values())\n",
    "    \n",
    "    else:\n",
    "        person_id = 711\n",
    "        person_ids = {}\n",
    "        files_to_skip = []\n",
    "\n",
    "    folders_to_keep = [str(folder) for folder in folders_to_keep]\n",
    "    \n",
    "    for folder in folders_to_keep:\n",
    "        folder_path = os.path.join(input_directory, folder)\n",
    "        \n",
    "        if os.path.isdir(folder_path):\n",
    "            for root, dirs, files in os.walk(input_directory):\n",
    "\n",
    "                for filename in files:\n",
    "                    if filename.endswith(\".dcm\") and filename not in files_to_skip:\n",
    "            #             if processed_count == 10:\n",
    "            #                 break\n",
    "\n",
    "                        input_file = os.path.join(root, filename)\n",
    "\n",
    "                        study_date = get_attribute_value(input_file,'Acquisition Date')\n",
    "\n",
    "                        if type(study_date) != str:\n",
    "                            break\n",
    "\n",
    "                        if not image_date_check(study_date):\n",
    "                            break \n",
    "\n",
    "                        study_time = get_attribute_value(input_file,'Acquisition Time')\n",
    "\n",
    "                        if type(study_time) == str:\n",
    "                            study_time = str(int(float(study_time)))\n",
    "                        else:\n",
    "                            continue\n",
    "\n",
    "\n",
    "                        series_num = convert_to_digits(get_attribute_value(input_file,'Series Number'),2)\n",
    "                        instance_num = convert_to_digits(get_attribute_value(input_file,'Instance Number'),3)\n",
    "                        mod = get_attribute_value(input_file,'Modality')\n",
    "                        acc_num = get_attribute_value(input_file,'Accession Number')\n",
    "                        study_desc = get_attribute_value(input_file,'Study Description')\n",
    "\n",
    "\n",
    "                        study_descs.append(study_desc)\n",
    "                        study_dates.append(study_date)\n",
    "                        study_times.append(study_time)\n",
    "                        series_nums.append(series_num)\n",
    "                        instance_nums.append(instance_num)\n",
    "                        accession_nums.append(acc_num)\n",
    "                        mods.append(mod)\n",
    "\n",
    "                        pre_file_name = input_file.replace(input_directory,\"\")\n",
    "                        path_folders = get_folders_in_path(pre_file_name)\n",
    "                        mrn = path_folders[0]\n",
    "\n",
    "                        if mrn not in person_ids.keys():\n",
    "                            person_id +=1\n",
    "                            person_ids[mrn] = person_id\n",
    "\n",
    "\n",
    "                        for i in range(0,len(folders_broken_out)):\n",
    "                            if len(path_folders) < 4:\n",
    "                                path_folders.append('')\n",
    "\n",
    "                            folders_broken_out[i].append(path_folders[i])\n",
    "\n",
    "\n",
    "                        \n",
    "                        old_names.append(filename)\n",
    "                        all_path_folders.append(path_folders)\n",
    "                        new_file_name = '{}_{}_{}_{}_{}_{}'.format(person_ids[mrn],study_date,study_time,mod,\n",
    "                                                                   series_num,instance_num) + os.path.splitext(filename)[1]\n",
    "\n",
    "                        output_folder = output_directory + str(person_ids[mrn]) + '/'\n",
    "\n",
    "                        if not os.path.exists(output_folder):\n",
    "                            os.makedirs(output_folder)\n",
    "                        output_file = os.path.join(output_folder, new_file_name)\n",
    "\n",
    "                        new_names.append(new_file_name)\n",
    "\n",
    "                        dicom_data = dcmread(input_file)\n",
    "                        remove_identifiers(dicom_data)\n",
    "                        replace_identifiers_with_pseudonyms(dicom_data)\n",
    "                        dcmwrite(output_file, dicom_data)\n",
    "\n",
    "                            ## Update CSV ##\n",
    "                        new_data = [filename, person_id, new_file_name, mrn, acc_num, mod, study_desc, study_date, study_time, \n",
    "                                       series_num, instance_num]\n",
    "                        update_csv(new_data, IMAGES_PROCESSED)\n",
    "\n",
    "                        processed_count +=1 \n",
    "\n",
    "    df = pd.DataFrame({\n",
    "                    'Old Name': old_names,\n",
    "                    'New Name': new_names,\n",
    "                    'MRN': folders_broken_out[0],\n",
    "                    'Accession_NBR': accession_nums,\n",
    "                    'Modality': mods,\n",
    "                    'Modality Subtype': study_descs,\n",
    "                    'Study Date':study_dates,\n",
    "                    'Study Time':study_times,\n",
    "                    'Series Number':series_nums,\n",
    "                    'Instance Number':instance_nums\n",
    "            })\n",
    "\n",
    "    \n",
    "    print(f\"Processed files in {input_directory} and saved to {output_directory}\")\n",
    "    print(df)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca6d9a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "INPUT_DIRECTORY = os.getenv(\"INPUT_DIRECTORY\")\n",
    "OUTPUT_DIRECTORY = os.getenv(\"OUTPUT_DIRECTORY\")\n",
    "df = batch_process_directory(INPUT_DIRECTORY,OUTPUT_DIRECTORY, skip_files = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6678cf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_csv(data, filename):\n",
    "    with open(filename, 'a', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e64bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patientid_list(input_directory):\n",
    "    \n",
    "    sampled_df = pd.read_csv('')\n",
    "\n",
    "    # Get the list of folders from the 'MRN' column\n",
    "    folders_to_keep = sampled_df['ACCESSIONNBR'].tolist()\n",
    "    \n",
    "    patient_ids_to_keep = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(input_directory):\n",
    "        for file in files:\n",
    "            input_file = os.path.join(root, file)\n",
    "            folder_path = get_folders_in_path(input_file)\n",
    "\n",
    "            if folder_path[2] in folders_to_keep:\n",
    "                patient_ids_to_keep.append(folder_path[1])\n",
    "                dirs[:] = []\n",
    "    print(len(set(patient_ids_to_keep)))\n",
    "                \n",
    "get_patientid_list(INPUT_DIRECTORY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgh_electroboost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
