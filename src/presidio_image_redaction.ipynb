{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1defb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import pydicom\n",
    "from presidio_image_redactor import DicomImageRedactorEngine\n",
    "from presidio_analyzer import PatternRecognizer, Pattern\n",
    "import numpy as np \n",
    "import cv2\n",
    "from pydicom.pixel_data_handlers.util import apply_voi_lut\n",
    "from skimage import exposure\n",
    "import dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ecdd43c",
   "metadata": {},
   "source": [
    "### This notebook contains code to handle pixel-level de-identification for DICOM images, primarily using the Microsoft Presidio open source library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5005fd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ResizeWithAspectRatio(image, width=None, height=None, inter=cv2.INTER_AREA):\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "    if width is None:\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "    else:\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    return cv2.resize(image, dim, interpolation=inter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f69876e",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65d799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "engine = DicomImageRedactorEngine()\n",
    "input_path = 'poster_image.dcm'\n",
    "ds = pydicom.dcmread(input_path)\n",
    "\n",
    "new_ds = Dataset()\n",
    "\n",
    "image = ds.pixel_array\n",
    "# image = exposure.equalize_adapthist(image)\n",
    "image = apply_voi_lut(image, ds)\n",
    "resize = ResizeWithAspectRatio(image, width=1280)\n",
    "ocr_kwargs = {\"ocr_threshold\": 0}\n",
    "\n",
    "\n",
    "new_ds.PixelData = image.tobytes()\n",
    "\n",
    "# new_ds.file_meta.TransferSyntaxUID = pydicom.uid.ImplicitVRLittleEndian\n",
    "# Set endianness and VR attributes\n",
    "new_ds.is_little_endian = True  # Set to True for little-endian\n",
    "new_ds.is_implicit_VR = False   # Set to False for explicit VR\n",
    "\n",
    "bits_allocated = ds.BitsAllocated\n",
    "bits_stored = ds.BitsStored\n",
    "high_bit = ds.HighBit\n",
    "\n",
    "\n",
    "new_ds.BitsAllocated = ds.BitsAllocated\n",
    "new_ds.BitsStored = ds.BitsStored\n",
    "new_ds.HighBit = ds.HighBit\n",
    "\n",
    "\n",
    "#Save the new DICOM instance to a file\n",
    "dcmwrite(\"new_file.dcm\", new_ds)\n",
    "\n",
    "new_ds = pydicom.dcmread(\"new_file.dcm\", force=True)\n",
    "\n",
    "new_ds.file_meta.TransferSyntaxUID = pydicom.uid.ImplicitVRLittleEndian\n",
    "\n",
    "\n",
    "redacted_dicom_instance = engine.redact(new_ds, fill=\"contrast\", ocr_kwargs=ocr_kwargs, \n",
    "                                        ad_hoc_recognizers=[name_recognizer, phone_number_recognizer])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cv2.imshow(\"dicom\", resize)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e0f965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_dicom_images(\n",
    "    instance_original: pydicom.dataset.FileDataset,\n",
    "    instance_redacted: pydicom.dataset.FileDataset,\n",
    "    figsize: tuple = (250, 250)) -> None:\n",
    "    \n",
    "    \"\"\"Display the DICOM pixel arrays of both original and redacted as images.\n",
    "\n",
    "    Args:\n",
    "        instance_original (pydicom.dataset.FileDataset): A single DICOM instance (with text PHI).\n",
    "        instance_redacted (pydicom.dataset.FileDataset): A single DICOM instance (redacted PHI).\n",
    "        figsize (tuple): Figure size in inches (width, height).\n",
    "    \"\"\"\n",
    "    \n",
    "#     original_image = instance_original.pixel_array.transpose(1, 2, 0)\n",
    "#     redacted_image = instance_redacted.pixel_array.transpose(1, 2, 0)\n",
    "    original_image = instance_original.pixel_array\n",
    "    redacted_image = instance_redacted.pixel_array\n",
    "    \n",
    "    _, ax = plt.subplots(1, 2, figsize=figsize)\n",
    "    ax[0].imshow(original_image, cmap=\"gray\")\n",
    "    ax[0].set_title('Original')\n",
    "    ax[1].imshow(redacted_image, cmap=\"gray\")\n",
    "    ax[1].set_title('Redacted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0098e3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom recognizer\n",
    "class NameRecognizer(PatternRecognizer):\n",
    "    def __init__(self):\n",
    "        pattern = Pattern(name=\"NAME_PATTERN\", regex=r\"[A-Za-z]+,\\s[A-Za-z]+\\s[A-Za-z]\", score=0.8)\n",
    "        super().__init__(supported_entity=\"PERSON_NAME\", patterns=[pattern])\n",
    "\n",
    "    # Instantiate the custom recognizer\n",
    "name_recognizer = NameRecognizer()\n",
    "\n",
    "# Define a custom recognizer for phone numbers\n",
    "class PhoneNumberRecognizer(PatternRecognizer):\n",
    "    def __init__(self):\n",
    "        pattern = Pattern(name=\"PHONE_PATTERN\", regex=r\" Mobile: \", score=0.99)\n",
    "        super().__init__(supported_entity=\"PHONE_NUMBER\", patterns=[pattern])\n",
    "\n",
    "# Instantiate the custom recognizer\n",
    "phone_number_recognizer = PhoneNumberRecognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1c5de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dotenv.load_dotenv(\"../config/.env\")\n",
    "os.getenv()\n",
    "\n",
    "# Set input and output paths\n",
    "INPUT_PATH = os.getenv(\"INPUT_PATH\")\n",
    "INPUT_PATH2 = os.getenv(\"INPUT_PATH2\")\n",
    "OUTPUT_DIR = os.getenv(\"OUTPUT_DIR\")\n",
    "INPUT_DIR = os.getenv(\"INPUT_DIR\")\n",
    "# Initialize the engine\n",
    "engine = DicomImageRedactorEngine()\n",
    "ocr_kwargs = {\"ocr_threshold\": 0}\n",
    "# Option 1: Redact from a loaded DICOM image\n",
    "dicom_instance = pydicom.dcmread(INPUT_PATH2)\n",
    "\n",
    "redacted_dicom_instance = engine.redact(dicom_instance, fill=\"contrast\", ocr_kwargs=ocr_kwargs, \n",
    "                                        ad_hoc_recognizers=[name_recognizer, phone_number_recognizer])\n",
    "\n",
    "\n",
    "\n",
    "compare_dicom_images(dicom_instance, redacted_dicom_instance)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mgh_electroboost",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
